# Training configuration file for the GNN model (CHAT GPT GENERATED)

# General settings
seed: 42                          # Random seed for reproducibility
output_dir: './train_runs'            # Directory to save outputs (models, logs, etc.)
wandb: true                       # Enable Weights & Biases logging
wandb_project: 'mphil_project'  # Weights & Biases project name

# Data settings
data_dir: 'data/4_body_spring_2d'                # Root directory for the dataset
quick_test: false                 # If true, use smaller subsets of the dataset for quick testing

# Model settings
model: gnn                # Model name (should match a model in model_factory)
model_params:                     # Parameters for the model initialization
  n_f: 6                         # Example model parameter (number of features)
  msg_dim: 100                     # Example model parameter (message dimension)
  ndim: 2                        # Example model parameter (node dimension)
  hidden: 300                     # Example model parameter (hidden layer size)
  aggr: 'add'                     # Example model parameter (aggregation method)

# Training settings
epochs: 10                       # Number of epochs to train
train_batch_size: 64              # Training batch size
val_batch_size: 1024                # Validation batch size
lr: 0.001                         # Learning rate
weight_decay: 1.0e-8                # Weight decay for the optimizer (L2 regularization)
save_every_n_epochs: 5            # Frequency of saving model weights (in epochs)

# Scheduler settings
scheduler_params:                 # Parameters for the learning rate scheduler
  max_lr: 0.001                   # Maximum learning rate
  final_div_factor: 1.0e+5           # Final division factor for the scheduler

# Loss settings
loss: 'loss+l1reg'      # Loss function name (should match a loss in loss_factory)
loss_params:                      # Parameters for the loss function initialization
  square: false                    # Example loss parameter (use squared error)
  l1_weight: 1.0e-2                 # Example loss parameter (weight for L1 regularization)

# # Transforms settings
# pre_transforms:                   # Pre-transforms to apply to the dataset
#   - 'Transform1'                  # Replace with actual transform names and parameters
#   - 'Transform2'                  # Example: [ 'Transform1', 'Transform2' ]
# augmentations:                    # Augmentations to apply during training
#   - 'Augmentation1'               # Replace with actual augmentation names and parameters
#   - 'Augmentation2'               # Example: [ 'Augmentation1', 'Augmentation2' ]

# Example specific settings (if applicable)
# These settings are placeholders and should be adapted to your specific model and dataset.
# example_param1: 'value1'
# example_param2: 'value2'
